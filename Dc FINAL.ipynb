{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math \n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import os\n",
    "import datetime\n",
    "import json as js\n",
    "import sqlite3 as sql\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import sqlite3\n",
    "\n",
    "# next command ensures that plots appear inside the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # also improves the look of plots\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = 10, 5  # default hor./vert. size of plots, in inches\n",
    "plt.rcParams['lines.markeredgewidth'] = 1  # to fix issue with seaborn box plots; needed after import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from palpatine import Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_sql(input_stuff, output):\n",
    "    \"\"\" \n",
    "    Export data to an SQLite database. Creates 4 tables (main, users, replies, hashtags) and uses the attributes \\n\n",
    "    from the JSON file.\n",
    "\n",
    "    Attributes\n",
    "    directory - Absolute directory of the folder with the files to be added\n",
    "    output - Name of the output file (.db)\n",
    "    \"\"\"\n",
    "\n",
    "    con = sql.connect(f'{output}.db')\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    palpatine = Sentiment()\n",
    "\n",
    "    # Lists for each table\n",
    "\n",
    "    # main\n",
    "    tweet_id, user_id, tweet_time, tweet_text, favourites, retweets, truncated, tweet_lang, sent = [[] for i in range(9)]\n",
    "\n",
    "    # users\n",
    "    screen_name, user_created, user_lang, user_desc, verified, followers, default_prof = [[] for i in range(7)]\n",
    "    default_prof_image, username = [[] for i in range(2)]\n",
    "\n",
    "    # replies\n",
    "    reply_id, reply_user = [[] for i in range(2)]\n",
    "\n",
    "    # hashtags\n",
    "    hashtags = []\n",
    "\n",
    "    def get_attrib(file):\n",
    "        with jsonlines.open(file, mode='r') as main:\n",
    "            for line in main.iter(allow_none=True, skip_invalid=True, skip_empty=True):\n",
    "                \n",
    "                # Remove deleted messages from stream\n",
    "                if \"created_at\" not in line:\n",
    "                    continue\n",
    "                \n",
    "                # Table 1 (main)\n",
    "                tweet_id.append(line['id_str'])\n",
    "                user_id.append(line['user']['id_str'])\n",
    "                tweet_time.append(datetime.datetime.strptime(line['created_at'], '%a %b %d %H:%M:%S %z %Y'))\n",
    "                favourites.append(line['favorite_count'])\n",
    "                retweets.append(line['retweet_count'])\n",
    "                truncated.append(line['truncated'])\n",
    "                text = line['text']\n",
    "                tweet_text.append(text)\n",
    "                \n",
    "                if 'lang' in line:\n",
    "                    lang = line['lang']\n",
    "                    tweet_lang.append(lang)\n",
    "                    if lang == 'en':\n",
    "                        score = vader.polarity_scores(text)['compound']\n",
    "                        sent.append(score)\n",
    "                    else:\n",
    "                        score = palpatine.basic_polarity(tweet=text, language=lang)\n",
    "                        if isinstance(score, dict):\n",
    "                            sent.append(score['compound'])\n",
    "                        else:\n",
    "                            sent.append(score)\n",
    "\n",
    "                else:\n",
    "                    tweet_lang.append('N/A')\n",
    "                    sent.append('N/A') \n",
    "\n",
    "                # Table 2 (users)\n",
    "                screen_name.append(line['user']['screen_name'])\n",
    "                user_created.append(datetime.datetime.strptime(line['user']['created_at'], '%a %b %d %H:%M:%S %z %Y').date())\n",
    "                user_lang.append(line['user']['lang'])\n",
    "                user_desc.append(line['user']['description'])\n",
    "                verified.append(line['user']['verified'])\n",
    "                followers.append(line['user']['followers_count'])\n",
    "                default_prof.append(line['user']['default_profile'])\n",
    "                default_prof_image.append(line['user']['default_profile_image'])\n",
    "                username.append(line['user']['name'])\n",
    "\n",
    "                # Table 3 (replies)\n",
    "                reply_id.append(line['in_reply_to_status_id_str'])\n",
    "                reply_user.append(line['in_reply_to_user_id_str'])\n",
    "\n",
    "                # Table 4 (hashtags)\n",
    "                temp_3 = [x['text'] for x in line['entities']['hashtags']]\n",
    "                if len(temp_3) == 0:\n",
    "                    hashtags.append(None)\n",
    "                else:\n",
    "                    hashtags.append(temp_3)\n",
    "        \n",
    "    if os.path.isdir(input_stuff):\n",
    "        files = [f'{input_stuff}/{x}' for x in os.listdir(input_stuff)]\n",
    "        for file in files:\n",
    "            get_attrib(file)\n",
    "    else:\n",
    "        get_attrib(input_stuff)\n",
    "\n",
    "    main_dict = {\n",
    "        'ID': tweet_id,\n",
    "        'User ID': user_id,\n",
    "        'Created At': tweet_time,\n",
    "        'Text': tweet_text,\n",
    "        'Language': tweet_lang,\n",
    "        'Sentiment': sent,\n",
    "        'Favourites': favourites,\n",
    "        'Retweets': retweets,\n",
    "        'Truncated': truncated\n",
    "    }\n",
    "\n",
    "    users_dict = {\n",
    "        'User ID': user_id,\n",
    "        'Date Created': user_created,\n",
    "        'Screen Name': screen_name,\n",
    "        'Name': username,\n",
    "        'Description': user_desc,\n",
    "        'Verified': verified,\n",
    "        'Follower Count': followers,\n",
    "        'Language': user_lang,\n",
    "        'Default Profile': default_prof,\n",
    "        'Default Profile Image': default_prof_image\n",
    "\n",
    "    }\n",
    "\n",
    "    temp_1, temp_2, temp_3 = [[] for i in range(3)]\n",
    "\n",
    "    for x, v, z in zip(tweet_id, reply_id, reply_user):\n",
    "        if v is None:\n",
    "            continue\n",
    "        temp_1.append(x)\n",
    "        temp_2.append(v)\n",
    "        temp_3.append(z)\n",
    "\n",
    "    replies_dict = {\n",
    "        'ID': temp_1,\n",
    "        'Reply ID': temp_2,\n",
    "        'Reply User': temp_3\n",
    "    }\n",
    "\n",
    "    temp_1 = [(i, x) for i, v in zip(tweet_id, hashtags) if v is not None for x in v]\n",
    "\n",
    "    hashtags_dict = {\n",
    "        'ID': [x[0] for x in temp_1],\n",
    "        'Hashtag': [x[1] for x in temp_1]\n",
    "    }\n",
    "\n",
    "    # Dataframes\n",
    "    df_main = pd.DataFrame(main_dict)\n",
    "    df_users = pd.DataFrame(users_dict)\n",
    "    df_replies = pd.DataFrame(replies_dict)\n",
    "    df_hashtags = pd.DataFrame(hashtags_dict)\n",
    "\n",
    "    # Dataframe cleaning\n",
    "    df_main.drop_duplicates(subset=['ID'], keep='first', inplace=True)\n",
    "    df_hashtags.drop_duplicates(keep='last', inplace=True)\n",
    "    df_replies.drop_duplicates(subset=['ID'], keep='last', inplace=True)\n",
    "    df_users.drop_duplicates(subset=['User ID'], keep='last', inplace=True)\n",
    "\n",
    "    # Schemas (Don't worry about it, you don't really need to know what this does)\n",
    "    dtypes_1 = {\n",
    "        'ID': 'TEXT',\n",
    "        'User ID': 'TEXT',\n",
    "        'Created At': 'TEXT',\n",
    "        'Language': 'TEXT',\n",
    "        'Text': 'TEXT',\n",
    "        'Sentiment': 'REAL',\n",
    "        'Retweets': 'INT',\n",
    "        'Favourites': 'INT',\n",
    "        'Truncated': 'INT'\n",
    "    }\n",
    "\n",
    "    dtypes_2 = {\n",
    "        'User ID': 'TEXT',\n",
    "        'Screen Name': 'TEXT',\n",
    "        'Name': 'TEXT',\n",
    "        'Date Created': 'NUMERIC',\n",
    "        'Description': 'TEXT',\n",
    "        'Verified': 'INT',\n",
    "        'Follower Count': 'INT',\n",
    "        'Language': 'TEXT',\n",
    "        'Default Profile': 'INT',\n",
    "        'Default Profile Image': 'INT'\n",
    "    }\n",
    "\n",
    "    dtypes_3 = {\n",
    "        'ID': 'TEXT',\n",
    "        'Reply ID': 'TEXT',\n",
    "        'Reply User': 'TEXT'\n",
    "    }\n",
    "\n",
    "    dtypes_4 = {\n",
    "        'ID': 'TEXT',\n",
    "        'Hashtag': 'TEXT'\n",
    "    }\n",
    "\n",
    "    df_main.to_sql('main', con, if_exists='append', index=False, dtype=dtypes_1)\n",
    "    df_users.to_sql('users', con, if_exists='append', index=False, dtype=dtypes_2)\n",
    "    df_replies.to_sql('replies', con, if_exists='append', index=False, dtype=dtypes_3)\n",
    "    df_hashtags.to_sql('hashtag', con, if_exists='append', index=False, dtype=dtypes_4)\n",
    "\n",
    "    con.close()\n",
    "\n",
    "directory = input('Enter the absolute directory of the folder with the files: ')\n",
    "output_file = input('Enter the name of the database: ')\n",
    "\n",
    "export_to_sql(directory, output_file)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sql.connect(\"demo.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM main\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = \"\"\"\n",
    "SELECT *\n",
    "FROM  main \n",
    "\"\"\"\n",
    "df_complete = pd.read_sql_query(all_tweets, conn)\n",
    "time_dict = df_complete.set_index('ID')['Created At'].to_dict()\n",
    "tweet_user_dict = df_complete.set_index('ID')['User ID'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_BA_total = \"\"\"\n",
    "SELECT Date(\"Created At\") as date, count(Text) as tweet_volume, main.*\n",
    "FROM main\n",
    "WHERE text LIKE \\\"%British_Airways%\\\"\n",
    "GROUP BY Date(\"Created At\")\n",
    "\"\"\"\n",
    "\n",
    "query_KLM_total = \"\"\"\n",
    "SELECT Date(\"Created At\") as date, count(Text) as tweet_volume, main.*\n",
    "FROM main\n",
    "WHERE text LIKE \\\"%KLM%\\\" \n",
    "GROUP BY Date(\"Created At\")\n",
    "\"\"\"\n",
    "\n",
    "df_BA_complete = pd.read_sql_query(query_BA_total, conn)\n",
    "df_KLM_complete = pd.read_sql_query(query_KLM_total, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_BA_total = \"\"\"\n",
    "SELECT *\n",
    "FROM main\n",
    "WHERE text LIKE \\\"%British_Airways%\\\"\n",
    "\"\"\"\n",
    "\n",
    "query_KLM_total = \"\"\"\n",
    "SELECT *\n",
    "FROM main\n",
    "WHERE text LIKE \\\"%KLM%\\\" \n",
    "\"\"\"\n",
    "\n",
    "query_BA_sent = \"\"\"\n",
    "SELECT *\n",
    "FROM main\n",
    "WHERE \"User ID\" = \"18332190\"\n",
    "\"\"\"\n",
    "\n",
    "query_KLM_sent = \"\"\"\n",
    "SELECT *\n",
    "FROM main\n",
    "WHERE \"User ID\" = \"56377143\"\n",
    "\"\"\"\n",
    "\n",
    "df_ba_total = pd.read_sql_query(query_BA_total, conn)\n",
    "df_klm_total = pd.read_sql_query(query_KLM_total, conn)\n",
    "df_ba_sent = pd.read_sql_query(query_BA_sent, conn)\n",
    "df_klm_sent = pd.read_sql_query(query_KLM_sent, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_KLM_test = \"\"\"\n",
    "SELECT *\n",
    "FROM main\n",
    "WHERE text LIKE \\\"%KLM%\\\" AND text LIKE \\\"%fucking%\\\" AND text LIKE \\\"%love%\\\"\n",
    "\"\"\"\n",
    "df_klm_test = pd.read_sql_query(query_KLM_test, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_klm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in df_klm_test[\"Text\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_time_tweets_klm = df_klm_total[[\"Created At\", \"Text\"]].copy()\n",
    "df_time_tweets_ba = df_ba_total[[\"Created At\", \"Text\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_BA_complete = df_BA_complete[[\"tweet_volume\", \"date\"]].copy()\n",
    "df_KLM_complete = df_KLM_complete[[\"tweet_volume\", \"date\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#heatmaps for tweet volume KLM compared to BA\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize = (20, 5))\n",
    "\n",
    "df_test_KLM = df_KLM_complete.copy()\n",
    "df_test_KLM[\"date_test\"] = pd.to_datetime(df_test_KLM[\"date\"])\n",
    "df_test_KLM[\"Month\"] = df_test_KLM[\"date_test\"].apply(lambda x:x.strftime(\"%b\"))\n",
    "df_test_KLM[\"Day\"] = df_test_KLM[\"date_test\"].apply(lambda x:x.day)\n",
    "\n",
    "matrix_heatmap_KLM = df_test_KLM.pivot(\"Month\", \"Day\", \"tweet_volume\")\n",
    "levels_heatmap_KLM = [i[:3] for i in [\"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\",\"January\", \"February\", \"March\"]]\n",
    "matrix_heatmap_KLM = matrix_heatmap_KLM.reindex_axis(axis = 0, labels = levels_heatmap_KLM)\n",
    "\n",
    "sns.heatmap(matrix_heatmap_KLM, ax = ax[0,0], vmin = 0, vmax = 20000)\n",
    "ax[0,0].set_title(\"Tweet volume for tweets related to KLM per month per day\", size=16, weight='bold')\n",
    "ax[0,0].set_ylabel(\"Month\")\n",
    "ax[0,0].set_xlabel(\"Day\");\n",
    "\n",
    "df_test = df_BA_complete.copy()\n",
    "df_test[\"date_test\"] = pd.to_datetime(df_test[\"date\"])\n",
    "df_test[\"Month\"] = df_test[\"date_test\"].apply(lambda x:x.strftime(\"%b\"))\n",
    "df_test[\"Day\"] = df_test[\"date_test\"].apply(lambda x:x.day)\n",
    "\n",
    "matrix_heatmap = df_test.pivot(\"Month\", \"Day\", \"tweet_volume\")\n",
    "levels_heatmap = [i[:3] for i in [\"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\",\"January\", \"February\", \"March\"]]\n",
    "matrix_heatmap = matrix_heatmap.reindex_axis(axis = 0, labels = levels_heatmap)\n",
    "\n",
    "sns.heatmap(matrix_heatmap, ax = ax[0, 1],  vmax = 20000)\n",
    "ax[0,1].set_title(\"Tweet volume for tweets related to British Airways per month per day\", size=16, weight='bold')\n",
    "ax[0,1].set_ylabel(\"Month\")\n",
    "ax[0,1].set_xlabel(\"Day\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code for conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting all the tweets with involvement from KLM\n",
    "conversations_KLM = \"\"\"\n",
    "SELECT \"Reply User\", replies.ID, replies.\"Reply ID\", \"User ID\", Date(\"Created At\") as Date\n",
    "FROM replies, main\n",
    "WHERE main.ID = replies.ID AND (\"Reply User\" = 56377143 or main.\"User ID\" = 56377143) \n",
    "ORDER BY \"Created At\" DESC\n",
    "\"\"\"\n",
    "df_conversations_KLM = pd.read_sql_query(conversations_KLM, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting everything based on the month for KLM\n",
    "may_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2016-05-01') & (df_conversations_KLM[\"Date\"]<= \"2016-05-31\")]\n",
    "june_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2016-06-01') & (df_conversations_KLM[\"Date\"]<= \"2016-06-31\")]\n",
    "july_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2016-07-01') & (df_conversations_KLM[\"Date\"]<= \"2016-07-31\")]\n",
    "aug_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2016-08-01') & (df_conversations_KLM[\"Date\"]<= \"2016-08-31\")]\n",
    "sep_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2016-09-01') & (df_conversations_KLM[\"Date\"]<= \"2016-09-31\")]\n",
    "oct_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2016-10-01') & (df_conversations_KLM[\"Date\"]<= \"2016-10-31\")]\n",
    "nov_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2016-11-01') & (df_conversations_KLM[\"Date\"]<= \"2016-11-31\")]\n",
    "dec_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2016-12-01') & (df_conversations_KLM[\"Date\"]<= \"2016-12-31\")]\n",
    "jan_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2017-01-01') & (df_conversations_KLM[\"Date\"]<= \"2017-01-31\")]\n",
    "feb_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2017-02-01') & (df_conversations_KLM[\"Date\"]<= \"2017-02-31\")]\n",
    "march_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2017-03-01') & (df_conversations_KLM[\"Date\"]<= \"2017-03-31\")]\n",
    "april_replies_df = df_conversations_KLM.loc[(df_conversations_KLM['Date'] >= '2017-04-01') & (df_conversations_KLM[\"Date\"]<= \"2017-04-31\")]\n",
    "\n",
    "may_replies_dict = may_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "june_replies_dict = june_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "july_replies_dict = july_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "aug_replies_dict = aug_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "sep_replies_dict = sep_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "oct_replies_dict = oct_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "nov_replies_dict = nov_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "dec_replies_dict = dec_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "jan_replies_dict = jan_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "feb_replies_dict = feb_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "march_replies_dict = march_replies_df.set_index('ID')['Reply ID'].to_dict()\n",
    "april_replies_dict = april_replies_df.set_index('ID')['Reply ID'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All conversation enders\n",
    "all_enders = \"\"\"\n",
    "SELECT replies.ID, \"Reply ID\", Date(\"Created At\") as Date\n",
    "FROM replies, main\n",
    "WHERE replies.ID = main.ID AND replies.ID NOT IN (SELECT \"Reply ID\" from replies) \n",
    "\n",
    "\"\"\"\n",
    "df_all_enders = pd.read_sql_query(all_enders, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting all the enders per month\n",
    "may_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2016-05-01') & (df_all_enders[\"Date\"]<= \"2016-05-31\")]\n",
    "june_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2016-06-01') & (df_all_enders[\"Date\"]<= \"2016-06-31\")]\n",
    "july_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2016-07-01') & (df_all_enders[\"Date\"]<= \"2016-07-31\")]\n",
    "aug_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2016-08-01') & (df_all_enders[\"Date\"]<= \"2016-08-31\")]\n",
    "sep_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2016-09-01') & (df_all_enders[\"Date\"]<= \"2016-09-31\")]\n",
    "oct_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2016-10-01') & (df_all_enders[\"Date\"]<= \"2016-10-31\")]\n",
    "nov_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2016-11-01') & (df_all_enders[\"Date\"]<= \"2016-11-31\")]\n",
    "dec_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2016-12-01') & (df_all_enders[\"Date\"]<= \"2016-12-31\")]\n",
    "jan_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2017-01-01') & (df_all_enders[\"Date\"]<= \"2017-01-31\")]\n",
    "feb_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2017-02-01') & (df_all_enders[\"Date\"]<= \"2017-02-31\")]\n",
    "march_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2017-03-01') & (df_all_enders[\"Date\"]<= \"2017-03-31\")]\n",
    "april_ender_df = df_all_enders.loc[(df_all_enders['Date'] >= '2017-04-01') & (df_all_enders[\"Date\"]<= \"2017-04-31\")]\n",
    "\n",
    "ender_may = may_ender_df['ID'].tolist()\n",
    "ender_june = june_ender_df['ID'].tolist()\n",
    "ender_july = july_ender_df['ID'].tolist()\n",
    "ender_aug = aug_ender_df['ID'].tolist()\n",
    "ender_sep = sep_ender_df['ID'].tolist()\n",
    "ender_oct = oct_ender_df['ID'].tolist()\n",
    "ender_nov = nov_ender_df['ID'].tolist()\n",
    "ender_dec = dec_ender_df['ID'].tolist()\n",
    "ender_jan = jan_ender_df['ID'].tolist()\n",
    "ender_feb = feb_ender_df['ID'].tolist()\n",
    "ender_march = march_ender_df['ID'].tolist()\n",
    "ender_april = april_ender_df['ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def month_con_dict (lst: list, replies: dict):\n",
    "    \"\"\" takes ender_month as lst and month_replies_dict as replies\n",
    "    returns a dictionary with all conversations of that month \n",
    "    \"\"\"\n",
    "    con_dict = {}\n",
    "    for i in lst:\n",
    "        if i in replies:\n",
    "            con_dict[i] = []\n",
    "    for k,v in con_dict.items():\n",
    "        v.insert(0,k)\n",
    "        current = k\n",
    "        for i in replies:\n",
    "            if current == i:\n",
    "                current = replies[i]\n",
    "                v.append(current)\n",
    "    return con_dict\n",
    "may_con_dict = month_con_dict (ender_may, may_replies_dict)\n",
    "june_con_dict = month_con_dict (ender_june, june_replies_dict)\n",
    "july_con_dict = month_con_dict (ender_july, july_replies_dict)\n",
    "aug_con_dict = month_con_dict (ender_aug, aug_replies_dict)\n",
    "sep_con_dict = month_con_dict (ender_sep, sep_replies_dict)\n",
    "oct_con_dict = month_con_dict (ender_oct, oct_replies_dict)\n",
    "nov_con_dict = month_con_dict (ender_nov, nov_replies_dict)\n",
    "dec_con_dict = month_con_dict (ender_dec, dec_replies_dict)\n",
    "jan_con_dict = month_con_dict (ender_jan, jan_replies_dict)\n",
    "feb_con_dict = month_con_dict (ender_feb, feb_replies_dict)\n",
    "march_con_dict = month_con_dict (ender_march, march_replies_dict)\n",
    "april_con_dict = month_con_dict (ender_april, april_replies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_first_klm (con_dict: dict):\n",
    "    \"\"\"takes month_con_dict\n",
    "    returns a dictionary with last_first tweets in a conversation\n",
    "    \"\"\"\n",
    "    con_user = {}\n",
    "    for k ,v in con_dict.items():\n",
    "        value_list = []\n",
    "        con_user[k] = value_list\n",
    "        for i in v:\n",
    "            if i in tweet_user_dict:\n",
    "                n = tweet_user_dict[i]\n",
    "                value_list.append(n)\n",
    "        if len(con_user[k]) < 3 or len(set(con_user[k])) != 2:\n",
    "            del con_user[k]\n",
    "    con_dict_final = {}\n",
    "    for k, v in con_user.items():\n",
    "        i = 0\n",
    "        j = -1\n",
    "        if v[i] == '56377143':\n",
    "            i += 1\n",
    "        if v[j] == '56377143':\n",
    "            j -= 1\n",
    "        n = '56377143'\n",
    "        if n in v[i+1:j]:\n",
    "            i = v.index(n)-1\n",
    "            con_dict_final [k] = [con_dict[k][i],con_dict[k][j]]\n",
    "    return con_dict_final\n",
    "may_con_dict_final = last_first_klm(may_con_dict) \n",
    "june_con_dict_final = last_first_klm(june_con_dict)   \n",
    "july_con_dict_final = last_first_klm(july_con_dict) \n",
    "aug_con_dict_final = last_first_klm(aug_con_dict) \n",
    "sep_con_dict_final = last_first_klm(sep_con_dict) \n",
    "oct_con_dict_final = last_first_klm(oct_con_dict) \n",
    "nov_con_dict_final = last_first_klm(nov_con_dict) \n",
    "dec_con_dict_final = last_first_klm(dec_con_dict) \n",
    "jan_con_dict_final = last_first_klm(jan_con_dict) \n",
    "feb_con_dict_final = last_first_klm(feb_con_dict) \n",
    "march_con_dict_final = last_first_klm(march_con_dict) \n",
    "april_con_dict_final = last_first_klm(april_con_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updated_lentgh (dictionary : dict):\n",
    "    \"\"\"average length and count of conversations\n",
    "    input should be month_con_dict\n",
    "    \"\"\"\n",
    "    con_length = 0\n",
    "    count = 0\n",
    "    for k,v in dictionary.items():\n",
    "        if len(v) > 2:\n",
    "            count += 1\n",
    "            con_length +=  len(v)\n",
    "    avr_len = con_length/ count\n",
    "    return (avr_len, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in May for KLM\n",
    "try: \n",
    "    KLM_may_avg = updated_lentgh(may_con_dict)[0]\n",
    "    KLM_may_total = updated_lentgh(may_con_dict)[1]\n",
    "        \n",
    "except: \n",
    "    KLM_may_avg = 0\n",
    "    KLM_may_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in June for KLM\n",
    "try: \n",
    "    KLM_june_avg = updated_lentgh(june_con_dict)[0]\n",
    "    KLM_june_total = updated_lentgh(june_con_dict)[1]\n",
    "    \n",
    "except:\n",
    "    KLM_june_avg = 0\n",
    "    KLM_june_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in July for KLM\n",
    "try:\n",
    "    KLM_july_avg = updated_lentgh(july_con_dict)[0]\n",
    "    KLM_july_total = updated_lentgh(july_con_dict)[1]\n",
    "    \n",
    "except:\n",
    "    KLM_july_avg = 0\n",
    "    KLM_july_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in August for KLM\n",
    "try:\n",
    "    KLM_august_avg = updated_lentgh(aug_con_dict)[0]\n",
    "    KLM_august_total = updated_lentgh(aug_con_dict)[1]\n",
    "\n",
    "except:\n",
    "    KLM_august_avg = 0\n",
    "    KLM_august_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in September for KLM\n",
    "try:\n",
    "    KLM_september_avg = updated_lentgh(sep_con_dict)[0]\n",
    "    KLM_september_total = updated_lentgh(sep_con_dict)[1]\n",
    "\n",
    "except:\n",
    "    KLM_september_avg = 0\n",
    "    KLM_september_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in October for KLM\n",
    "try:\n",
    "    KLM_october_avg = updated_lentgh(oct_con_dict)[0]\n",
    "    KLM_october_total = updated_lentgh(oct_con_dict)[1]\n",
    "\n",
    "except:\n",
    "    KLM_october_avg = 0\n",
    "    KLM_october_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in November for KLM\n",
    "try: \n",
    "    KLM_november_avg = updated_lentgh(nov_con_dict)[0]\n",
    "    KLM_november_total = updated_lentgh(nov_con_dict)[1]\n",
    "\n",
    "except: \n",
    "    KLM_november_avg = 0\n",
    "    KLM_november_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in December for KLM\n",
    "try: \n",
    "    KLM_december_avg = updated_lentgh(dec_con_dict)[0]\n",
    "    KLM_december_total = updated_lentgh(dec_con_dict)[1]\n",
    "\n",
    "except:\n",
    "    KLM_december_avg = 0\n",
    "    KLM_december_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in January for KLM\n",
    "try:\n",
    "    KLM_january_avg = updated_lentgh(jan_con_dict)[0]\n",
    "    KLM_january_total = updated_lentgh(jan_con_dict)[1]\n",
    "\n",
    "except:\n",
    "    KLM_january_avg = 0\n",
    "    KLM_january_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in February for KLM\n",
    "try:\n",
    "    KLM_february_avg = updated_lentgh(feb_con_dict)[0]\n",
    "    KLM_february_total = updated_lentgh(feb_con_dict)[1]\n",
    "\n",
    "except:\n",
    "    KLM_february_avg = 0\n",
    "    KLM_february_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in March for KLM\n",
    "try:\n",
    "    KLM_march_avg = updated_lentgh(march_con_dict)[0]\n",
    "    KLM_march_total = updated_lentgh(march_con_dict)[1]\n",
    "\n",
    "except:\n",
    "    KLM_march_avg = 0\n",
    "    KLM_march_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in April for KLM\n",
    "try:\n",
    "    KLM_april_avg = updated_lentgh(april_con_dict)[0]\n",
    "    KLM_april_total = updated_lentgh(april_con_dict)[1]\n",
    "    \n",
    "except:\n",
    "    KLM_april_avg = 0\n",
    "    KLM_april_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sentiment delta code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_dict = df_complete.set_index('ID')['Sentiment'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_delta_init_end (dictionary):\n",
    "    \"\"\" takes dictionary like june_con_dict_final\n",
    "    returns a dictionary with conversations' enders with the sentiment delta they created\n",
    "    \"\"\"\n",
    "    new_dict = {}\n",
    "    for k in dictionary:\n",
    "        if dictionary[k][0] in sentiment_dict and dictionary[k][1] in sentiment_dict:\n",
    "            last_sent = sentiment_dict[dictionary[k][0]]\n",
    "            first_sent = sentiment_dict[dictionary[k][1]]\n",
    "            if type(last_sent) is float and type(first_sent) is float:\n",
    "                new_dict[k] = [last_sent, first_sent]\n",
    "    return (new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_new_test (lst):\n",
    "    list_sentiment = []\n",
    "    for i in lst:\n",
    "        delta = i[1] - i[0]\n",
    "        list_sentiment.append(delta)\n",
    "        \n",
    "    return list_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NEW CODE WITH CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#May is empty\n",
    "#in June 2 out of 13 go from positive to negative\n",
    "#July 92 out of 1268\n",
    "#August 86 out of 1130\n",
    "#September 88 out of 1324\n",
    "#October 55 out of 1113\n",
    "#November 29 out of 672\n",
    "#December 61 out of 982\n",
    "#January 7 out of 140\n",
    "#February 77 out of 944\n",
    "#March 49 out of 746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#June 15%\n",
    "#July 7.1%\n",
    "#August 7.6%\n",
    "#September 6.6%\n",
    "#October 4.9%\n",
    "#November 4.3%\n",
    "#December 6.2%\n",
    "#January 5%\n",
    "#February 8.2%\n",
    "#March 6.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "may_positive_KLM = []\n",
    "may_neutral_KLM = []\n",
    "may_negative_KLM = []\n",
    "may_sentiment_end_init = sentiment_delta_init_end(may_con_dict_final)\n",
    "for i in may_sentiment_end_init:\n",
    "    if may_sentiment_end_init[i][1] > 0:\n",
    "        may_positive_KLM.append(may_sentiment_end_init[i])\n",
    "    elif may_sentiment_end_init[i][1] < 0:\n",
    "        may_negative_KLM.append(may_sentiment_end_init[i])\n",
    "    else:\n",
    "        may_neutral_KLM.append(may_sentiment_end_init[i])   \n",
    "    \n",
    "may_positive_senti_KLM = sentiment_new_test(may_positive_KLM)\n",
    "may_negative_senti_KLM = sentiment_new_test(may_negative_KLM)\n",
    "may_neutral_senti_KLM = sentiment_new_test(may_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "june_positive_KLM = []\n",
    "june_neutral_KLM = []\n",
    "june_negative_KLM = []\n",
    "june_sentiment_end_init = sentiment_delta_init_end(june_con_dict_final)\n",
    "for i in june_sentiment_end_init:\n",
    "    if june_sentiment_end_init[i][1] > 0:\n",
    "        june_positive_KLM.append(june_sentiment_end_init[i])\n",
    "    elif june_sentiment_end_init[i][1] < 0:\n",
    "        june_negative_KLM.append(june_sentiment_end_init[i])\n",
    "    else:\n",
    "        june_neutral_KLM.append(june_sentiment_end_init[i]) \n",
    "    \n",
    "june_positive_senti_KLM = sentiment_new_test(june_positive_KLM)\n",
    "june_negative_senti_KLM = sentiment_new_test(june_negative_KLM)\n",
    "june_neutral_senti_KLM = sentiment_new_test(june_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "july_positive_KLM = []\n",
    "july_neutral_KLM = []\n",
    "july_negative_KLM = []\n",
    "july_sentiment_end_init = sentiment_delta_init_end(july_con_dict_final)\n",
    "for i in july_sentiment_end_init:\n",
    "    if july_sentiment_end_init[i][1] > 0:\n",
    "        july_positive_KLM.append(july_sentiment_end_init[i])\n",
    "    elif july_sentiment_end_init[i][1] < 0:\n",
    "        july_negative_KLM.append(july_sentiment_end_init[i])\n",
    "    else:\n",
    "        july_neutral_KLM.append(july_sentiment_end_init[i])  \n",
    "        \n",
    "july_positive_senti_KLM = sentiment_new_test(july_positive_KLM)\n",
    "july_negative_senti_KLM = sentiment_new_test(july_negative_KLM)\n",
    "july_neutral_senti_KLM = sentiment_new_test(july_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "august_positive_KLM = []\n",
    "august_neutral_KLM = []\n",
    "august_negative_KLM = []\n",
    "august_sentiment_end_init = sentiment_delta_init_end(aug_con_dict_final)\n",
    "for i in august_sentiment_end_init:\n",
    "    if august_sentiment_end_init[i][1] > 0:\n",
    "        august_positive_KLM.append(august_sentiment_end_init[i])\n",
    "    elif august_sentiment_end_init[i][1] < 0:\n",
    "        august_negative_KLM.append(august_sentiment_end_init[i])\n",
    "    else:\n",
    "        august_neutral_KLM.append(august_sentiment_end_init[i])  \n",
    "        \n",
    "august_positive_senti_KLM = sentiment_new_test(august_positive_KLM)\n",
    "august_negative_senti_KLM = sentiment_new_test(august_negative_KLM)\n",
    "august_neutral_senti_KLM = sentiment_new_test(august_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "september_positive_KLM = []\n",
    "september_neutral_KLM = []\n",
    "september_negative_KLM = []\n",
    "september_sentiment_end_init = sentiment_delta_init_end(sep_con_dict_final)\n",
    "for i in september_sentiment_end_init:\n",
    "    if september_sentiment_end_init[i][1] > 0:\n",
    "        september_positive_KLM.append(september_sentiment_end_init[i])\n",
    "    elif september_sentiment_end_init[i][1] < 0:\n",
    "        september_negative_KLM.append(september_sentiment_end_init[i])\n",
    "    else:\n",
    "        september_neutral_KLM.append(september_sentiment_end_init[i])  \n",
    "        \n",
    "september_positive_senti_KLM = sentiment_new_test(september_positive_KLM)\n",
    "september_negative_senti_KLM = sentiment_new_test(september_negative_KLM)\n",
    "september_neutral_senti_KLM = sentiment_new_test(september_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "october_positive_KLM = []\n",
    "october_neutral_KLM = []\n",
    "october_negative_KLM = []\n",
    "october_sentiment_end_init = sentiment_delta_init_end(oct_con_dict_final)\n",
    "for i in october_sentiment_end_init:\n",
    "    if october_sentiment_end_init[i][1] > 0:\n",
    "        october_positive_KLM.append(october_sentiment_end_init[i])\n",
    "    elif october_sentiment_end_init[i][1] < 0:\n",
    "        october_negative_KLM.append(october_sentiment_end_init[i])\n",
    "    else:\n",
    "        october_neutral_KLM.append(october_sentiment_end_init[i])  \n",
    "\n",
    "october_positive_senti_KLM = sentiment_new_test(october_positive_KLM)\n",
    "october_negative_senti_KLM = sentiment_new_test(october_negative_KLM)\n",
    "october_neutral_senti_KLM = sentiment_new_test(october_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "november_positive_KLM = []\n",
    "november_neutral_KLM = []\n",
    "november_negative_KLM = []\n",
    "november_sentiment_end_init = sentiment_delta_init_end(nov_con_dict_final)\n",
    "for i in november_sentiment_end_init:\n",
    "    if november_sentiment_end_init[i][1] > 0:\n",
    "        november_positive_KLM.append(november_sentiment_end_init[i])\n",
    "    elif november_sentiment_end_init[i][1] < 0:\n",
    "        november_negative_KLM.append(november_sentiment_end_init[i])\n",
    "    else:\n",
    "        november_neutral_KLM.append(november_sentiment_end_init[i])  \n",
    "\n",
    "november_positive_senti_KLM = sentiment_new_test(november_positive_KLM)\n",
    "november_negative_senti_KLM = sentiment_new_test(november_negative_KLM)\n",
    "november_neutral_senti_KLM = sentiment_new_test(november_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "december_positive_KLM = []\n",
    "december_neutral_KLM = []\n",
    "december_negative_KLM = []\n",
    "december_sentiment_end_init = sentiment_delta_init_end(dec_con_dict_final)\n",
    "for i in december_sentiment_end_init:\n",
    "    if december_sentiment_end_init[i][1] > 0:\n",
    "        december_positive_KLM.append(december_sentiment_end_init[i])\n",
    "    elif december_sentiment_end_init[i][1] < 0:\n",
    "        december_negative_KLM.append(december_sentiment_end_init[i])\n",
    "    else:\n",
    "        december_neutral_KLM.append(december_sentiment_end_init[i])  \n",
    "\n",
    "december_positive_senti_KLM = sentiment_new_test(november_positive_KLM)\n",
    "december_negative_senti_KLM = sentiment_new_test(november_negative_KLM)\n",
    "december_neutral_senti_KLM = sentiment_new_test(november_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "january_positive_KLM = []\n",
    "january_neutral_KLM = []\n",
    "january_negative_KLM = []\n",
    "january_sentiment_end_init = sentiment_delta_init_end(jan_con_dict_final)\n",
    "for i in january_sentiment_end_init:\n",
    "    if january_sentiment_end_init[i][1] > 0:\n",
    "        january_positive_KLM.append(january_sentiment_end_init[i])\n",
    "    elif january_sentiment_end_init[i][1] < 0:\n",
    "        january_negative_KLM.append(january_sentiment_end_init[i])\n",
    "    else:\n",
    "        january_neutral_KLM.append(january_sentiment_end_init[i])  \n",
    "\n",
    "january_positive_senti_KLM = sentiment_new_test(january_positive_KLM)\n",
    "january_negative_senti_KLM = sentiment_new_test(january_negative_KLM)\n",
    "january_neutral_senti_KLM = sentiment_new_test(january_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "february_positive_KLM = []\n",
    "february_neutral_KLM = []\n",
    "february_negative_KLM = []\n",
    "february_sentiment_end_init = sentiment_delta_init_end(feb_con_dict_final)\n",
    "for i in february_sentiment_end_init:\n",
    "    if february_sentiment_end_init[i][1] > 0:\n",
    "        february_positive_KLM.append(february_sentiment_end_init[i])\n",
    "    elif february_sentiment_end_init[i][1] < 0:\n",
    "        february_negative_KLM.append(february_sentiment_end_init[i])\n",
    "    else:\n",
    "        february_neutral_KLM.append(february_sentiment_end_init[i])  \n",
    "\n",
    "february_positive_senti_KLM = sentiment_new_test(february_positive_KLM)\n",
    "february_negative_senti_KLM = sentiment_new_test(february_negative_KLM)\n",
    "february_neutral_senti_KLM = sentiment_new_test(february_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "march_positive_KLM = []\n",
    "march_neutral_KLM = []\n",
    "march_negative_KLM = []\n",
    "march_sentiment_end_init = sentiment_delta_init_end(march_con_dict_final)\n",
    "for i in march_sentiment_end_init:\n",
    "    if march_sentiment_end_init[i][1] > 0:\n",
    "        march_positive_KLM.append(march_sentiment_end_init[i])\n",
    "    elif march_sentiment_end_init[i][1] < 0:\n",
    "        march_negative_KLM.append(march_sentiment_end_init[i])\n",
    "    else:\n",
    "        march_neutral_KLM.append(march_sentiment_end_init[i])  \n",
    "\n",
    "march_positive_senti_KLM = sentiment_new_test(march_positive_KLM)\n",
    "march_negative_senti_KLM = sentiment_new_test(march_negative_KLM)\n",
    "march_neutral_senti_KLM = sentiment_new_test(march_neutral_KLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KLM_total_positive = may_positive_senti_KLM + june_positive_senti_KLM + july_positive_senti_KLM + august_positive_senti_KLM+september_positive_senti_KLM + october_positive_senti_KLM + november_positive_senti_KLM +december_positive_senti_KLM + january_positive_senti_KLM + february_positive_senti_KLM+march_positive_senti_KLM\n",
    "KLM_total_negative = may_negative_senti_KLM + june_negative_senti_KLM + july_negative_senti_KLM + august_negative_senti_KLM+september_negative_senti_KLM + october_negative_senti_KLM + november_negative_senti_KLM +december_negative_senti_KLM + january_negative_senti_KLM + february_negative_senti_KLM+march_negative_senti_KLM\n",
    "KLM_total_neutral = may_neutral_senti_KLM + june_neutral_senti_KLM + july_neutral_senti_KLM + august_neutral_senti_KLM+september_neutral_senti_KLM + october_neutral_senti_KLM + november_neutral_senti_KLM +december_neutral_senti_KLM + january_neutral_senti_KLM + february_neutral_senti_KLM+march_neutral_senti_KLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount_positive_positive_KLM = 0\n",
    "amount_positive_negative_KLM = 0\n",
    "amount_positive_neutral_KLM = 0\n",
    "\n",
    "for i in KLM_total_positive:\n",
    "    if i < -0.25:\n",
    "        amount_positive_negative_KLM += 1\n",
    "    elif i > 0.25: \n",
    "        amount_positive_positive_KLM +=1\n",
    "    else:\n",
    "        amount_positive_neutral_KLM +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount_negative_positive_KLM = 0\n",
    "amount_negative_negative_KLM = 0\n",
    "amount_negative_neutral_KLM = 0\n",
    "\n",
    "for i in KLM_total_negative:\n",
    "    if i < -0.25:\n",
    "        amount_negative_negative_KLM += 1\n",
    "    elif i > 0.25: \n",
    "        amount_negative_positive_KLM +=1\n",
    "    else:\n",
    "        amount_negative_neutral_KLM +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount_neutral_positive_KLM = 0\n",
    "amount_neutral_negative_KLM = 0\n",
    "amount_neutral_neutral_KLM = 0\n",
    "\n",
    "for i in KLM_total_neutral:\n",
    "    if i < -0.25:\n",
    "        amount_neutral_negative_KLM += 1\n",
    "    elif i > 0.25: \n",
    "        amount_neutral_positive_KLM +=1\n",
    "    else:\n",
    "        amount_neutral_neutral_KLM +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change_KLM = pd.DataFrame({'index' : ['positive', 'negative', 'neutral'],'positive': [amount_positive_positive_KLM, amount_positive_negative_KLM, amount_positive_neutral_KLM], \n",
    "                       'Negative': [amount_negative_positive_KLM, amount_negative_negative_KLM, amount_negative_neutral_KLM],\n",
    "                     'Neutral' : [amount_neutral_positive_KLM, amount_neutral_negative_KLM, amount_neutral_neutral_KLM ]\n",
    "                    })\n",
    "change_KLM = change_KLM.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code conversations BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selecting all the tweets with involvement from BA\n",
    "conversations_BA = \"\"\"\n",
    "SELECT \"Reply User\", replies.ID, replies.\"Reply ID\", \"User ID\", Date(\"Created At\") as Date\n",
    "FROM replies, main\n",
    "WHERE main.ID = replies.ID AND (\"Reply User\" = 18332190 or main.\"User ID\" = 18332190) \n",
    "ORDER BY \"Created At\" DESC\n",
    "\"\"\"\n",
    "df_conversations_BA = pd.read_sql_query(conversations_BA, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting everything based on the month for BA\n",
    "may_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2016-05-01') & (df_conversations_BA[\"Date\"]<= \"2016-05-31\")]\n",
    "june_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2016-06-01') & (df_conversations_BA[\"Date\"]<= \"2016-06-31\")]\n",
    "july_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2016-07-01') & (df_conversations_BA[\"Date\"]<= \"2016-07-31\")]\n",
    "aug_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2016-08-01') & (df_conversations_BA[\"Date\"]<= \"2016-08-31\")]\n",
    "sep_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2016-09-01') & (df_conversations_BA[\"Date\"]<= \"2016-09-31\")]\n",
    "oct_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2016-10-01') & (df_conversations_BA[\"Date\"]<= \"2016-10-31\")]\n",
    "nov_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2016-11-01') & (df_conversations_BA[\"Date\"]<= \"2016-11-31\")]\n",
    "dec_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2016-12-01') & (df_conversations_BA[\"Date\"]<= \"2016-12-31\")]\n",
    "jan_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2017-01-01') & (df_conversations_BA[\"Date\"]<= \"2017-01-31\")]\n",
    "feb_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2017-02-01') & (df_conversations_BA[\"Date\"]<= \"2017-02-31\")]\n",
    "march_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2017-03-01') & (df_conversations_BA[\"Date\"]<= \"2017-03-31\")]\n",
    "april_replies_df_BA = df_conversations_BA.loc[(df_conversations_BA['Date'] >= '2017-04-01') & (df_conversations_BA[\"Date\"]<= \"2017-04-31\")]\n",
    "\n",
    "may_replies_dict_BA = may_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "june_replies_dict_BA = june_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "july_replies_dict_BA = july_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "aug_replies_dict_BA = aug_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "sep_replies_dict_BA = sep_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "oct_replies_dict_BA = oct_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "nov_replies_dict_BA = nov_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "dec_replies_dict_BA = dec_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "jan_replies_dict_BA = jan_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "feb_replies_dict_BA = feb_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "march_replies_dict_BA = march_replies_df_BA.set_index('ID')['Reply ID'].to_dict()\n",
    "april_replies_dict_BA = april_replies_df_BA.set_index('ID')['Reply ID'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def month_con_dict_BA (lst: list, replies: dict):\n",
    "    \"\"\" takes ender_month as lst and month_replies_dict_BA as replies\n",
    "    returns a dictionary with all conversations of that month from BA\n",
    "    \"\"\"\n",
    "    con_dict = {}\n",
    "    for i in lst:\n",
    "        if i in replies:\n",
    "            con_dict[i] = []\n",
    "    for k,v in con_dict.items():\n",
    "        v.insert(0,k)\n",
    "        current = k\n",
    "        for i in replies:\n",
    "            if current == i:\n",
    "                current = replies[i]\n",
    "                v.append(current)\n",
    "    return con_dict\n",
    "may_con_dict_BA = month_con_dict (ender_may, may_replies_dict_BA)\n",
    "june_con_dict_BA = month_con_dict (ender_june, june_replies_dict_BA)\n",
    "july_con_dict_BA = month_con_dict (ender_july, july_replies_dict_BA)\n",
    "aug_con_dict_BA = month_con_dict (ender_aug, aug_replies_dict_BA)\n",
    "sep_con_dict_BA = month_con_dict (ender_sep, sep_replies_dict_BA)\n",
    "oct_con_dict_BA = month_con_dict (ender_oct, oct_replies_dict_BA)\n",
    "nov_con_dict_BA = month_con_dict (ender_nov, nov_replies_dict_BA)\n",
    "dec_con_dict_BA = month_con_dict (ender_dec, dec_replies_dict_BA)\n",
    "jan_con_dict_BA = month_con_dict (ender_jan, jan_replies_dict_BA)\n",
    "feb_con_dict_BA = month_con_dict (ender_feb, feb_replies_dict_BA)\n",
    "march_con_dict_BA = month_con_dict (ender_march, march_replies_dict_BA)\n",
    "april_con_dict_BA = month_con_dict (ender_april, april_replies_dict_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_first_BA (con_dict: dict):\n",
    "    \"\"\"takes month_con_dict_BA\n",
    "    returns a dictionary with last_first tweets in a conversation\n",
    "    \"\"\"\n",
    "    con_user = {}\n",
    "    for k ,v in con_dict.items():\n",
    "        value_list = []\n",
    "        con_user[k] = value_list\n",
    "        for i in v:\n",
    "            if i in tweet_user_dict:\n",
    "                n = tweet_user_dict[i]\n",
    "                value_list.append(n)\n",
    "        if len(con_user[k]) < 3 or len(set(con_user[k])) != 2:\n",
    "            del con_user[k]\n",
    "    con_dict_final = {}\n",
    "    for k, v in con_user.items():\n",
    "        i = 0\n",
    "        j = -1\n",
    "        if v[i] == '18332190':\n",
    "            i += 1\n",
    "        if v[j] == '18332190':\n",
    "            j -= 1\n",
    "        n = '18332190'\n",
    "        if n in v[i+1:j]:\n",
    "            i = v.index(n)-1\n",
    "            con_dict_final [k] = [con_dict[k][i],con_dict[k][j]]\n",
    "    return con_dict_final\n",
    "may_con_dict_final_BA = last_first_BA(may_con_dict_BA) \n",
    "june_con_dict_final_BA = last_first_BA(june_con_dict_BA)   \n",
    "july_con_dict_final_BA = last_first_BA(july_con_dict_BA) \n",
    "aug_con_dict_final_BA = last_first_BA(aug_con_dict_BA) \n",
    "sep_con_dict_final_BA = last_first_BA(sep_con_dict_BA) \n",
    "oct_con_dict_final_BA = last_first_BA(oct_con_dict_BA) \n",
    "nov_con_dict_final_BA = last_first_BA(nov_con_dict_BA) \n",
    "dec_con_dict_final_BA = last_first_BA(dec_con_dict_BA) \n",
    "jan_con_dict_final_BA = last_first_BA(jan_con_dict_BA) \n",
    "feb_con_dict_final_BA = last_first_BA(feb_con_dict_BA) \n",
    "march_con_dict_final_BA = last_first_BA(march_con_dict_BA) \n",
    "april_con_dict_final_BA = last_first_BA(april_con_dict_BA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in May for BA\n",
    "try: \n",
    "    BA_may_avg = updated_lentgh(may_con_dict_BA)[0]\n",
    "    BA_may_total = updated_lentgh(may_con_dict_BA)[1]\n",
    "        \n",
    "except: \n",
    "    BA_may_avg = 0\n",
    "    BA_may_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in June for BA\n",
    "try:\n",
    "    BA_june_avg = updated_lentgh(june_con_dict_BA)[0]\n",
    "    BA_june_total = updated_lentgh(june_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_june_avg = 0\n",
    "    BA_june_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in July for BA\n",
    "try:\n",
    "    BA_july_avg = updated_lentgh(july_con_dict_BA)[0]\n",
    "    BA_july_total = updated_lentgh(july_con_dict_BA)[1]\n",
    "\n",
    "except:\n",
    "    BA_july_avg = 0\n",
    "    BA_july_total = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in August for BA\n",
    "try:\n",
    "    BA_august_avg = updated_lentgh(aug_con_dict_BA)[0]\n",
    "    BA_august_total = updated_lentgh(aug_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_august_avg = 0\n",
    "    BA_august_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in September for BA\n",
    "try:\n",
    "    BA_september_avg = updated_lentgh(sep_con_dict_BA)[0]\n",
    "    BA_september_total = updated_lentgh(sep_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_september_avg = 0\n",
    "    BA_september_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in October for BA\n",
    "try:\n",
    "    BA_october_avg = updated_lentgh(oct_con_dict_BA)[0]\n",
    "    BA_october_total = updated_lentgh(oct_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_october_avg = 0\n",
    "    BA_october_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in November for BA\n",
    "try:\n",
    "    BA_november_avg = updated_lentgh(nov_con_dict_BA)[0]\n",
    "    BA_november_total = updated_lentgh(nov_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_november_avg = 0\n",
    "    BA_november_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in December for BA\n",
    "try:  \n",
    "    BA_december_avg = updated_lentgh(dec_con_dict_BA)[0]\n",
    "    BA_december_total = updated_lentgh(dec_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_december_avg = 0\n",
    "    BA_december_total = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in January for BA\n",
    "try:\n",
    "    BA_january_avg = updated_lentgh(jan_con_dict_BA)[0]\n",
    "    BA_january_total = updated_lentgh(jan_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_january_avg = 0\n",
    "    BA_january_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in February for BA\n",
    "try:\n",
    "    BA_february_avg = updated_lentgh(feb_con_dict_BA)[0]\n",
    "    BA_february_total = updated_lentgh(feb_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_february_avg = 0\n",
    "    BA_february_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in March for BA\n",
    "try:\n",
    "    BA_march_avg = updated_lentgh(march_con_dict_BA)[0]\n",
    "    BA_march_total = updated_lentgh(march_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_march_avg = 0\n",
    "    BA_march_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average conversation length and amount of conversations in April for BA\n",
    "try:\n",
    "    BA_april_avg = updated_lentgh(april_con_dict_BA)[0]\n",
    "    BA_april_total = updated_lentgh(april_con_dict_BA)[1]\n",
    "    \n",
    "except:\n",
    "    BA_april_avg = 0\n",
    "    BA_april_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sentiment delta code BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "may_positive_BA = []\n",
    "may_neutral_BA = []\n",
    "may_negative_BA = []\n",
    "may_sentiment_end_init_BA = sentiment_delta_init_end(may_con_dict_final_BA)\n",
    "for i in may_sentiment_end_init_BA:\n",
    "    if may_sentiment_end_init_BA[i][1] > 0:\n",
    "        may_positive_BA.append(may_sentiment_end_init_BA[i])\n",
    "    elif may_sentiment_end_init_BA[i][1] < 0:\n",
    "        may_negative_BA.append(may_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        may_neutral_BA.append(may_sentiment_end_init_BA[i])   \n",
    "    \n",
    "may_positive_senti_BA = sentiment_new_test(may_positive_BA)\n",
    "may_negative_senti_BA = sentiment_new_test(may_negative_BA)\n",
    "may_neutral_senti_BA = sentiment_new_test(may_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "june_positive_BA = []\n",
    "june_neutral_BA = []\n",
    "june_negative_BA = []\n",
    "june_sentiment_end_init_BA = sentiment_delta_init_end(june_con_dict_final_BA)\n",
    "for i in june_sentiment_end_init_BA:\n",
    "    if june_sentiment_end_init_BA[i][1] > 0:\n",
    "        june_positive_BA.append(june_sentiment_end_init_BA[i])\n",
    "    elif june_sentiment_end_init_BA[i][1] < 0:\n",
    "        june_negative_KLM_BA.append(june_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        june_neutral_BA.append(june_sentiment_end_init_BA[i]) \n",
    "    \n",
    "june_positive_senti_BA = sentiment_new_test(june_positive_BA)\n",
    "june_negative_senti_BA = sentiment_new_test(june_negative_BA)\n",
    "june_neutral_senti_BA = sentiment_new_test(june_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "july_positive_BA = []\n",
    "july_neutral_BA = []\n",
    "july_negative_BA = []\n",
    "july_sentiment_end_init_BA = sentiment_delta_init_end(july_con_dict_final_BA)\n",
    "for i in july_sentiment_end_init_BA:\n",
    "    if july_sentiment_end_init_BA[i][1] > 0:\n",
    "        july_positive_BA.append(july_sentiment_end_init_BA[i])\n",
    "    elif july_sentiment_end_init_BA[i][1] < 0:\n",
    "        july_negative_BA.append(july_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        july_neutral_BA.append(july_sentiment_end_init_BA[i])  \n",
    "        \n",
    "july_positive_senti_BA = sentiment_new_test(july_positive_BA)\n",
    "july_negative_senti_BA = sentiment_new_test(july_negative_BA)\n",
    "july_neutral_senti_BA = sentiment_new_test(july_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "august_positive_BA = []\n",
    "august_neutral_BA = []\n",
    "august_negative_BA = []\n",
    "august_sentiment_end_init_BA = sentiment_delta_init_end(aug_con_dict_final_BA)\n",
    "for i in august_sentiment_end_init_BA:\n",
    "    if august_sentiment_end_init_BA[i][1] > 0:\n",
    "        august_positive_BA.append(august_sentiment_end_init_BA[i])\n",
    "    elif august_sentiment_end_init_BA[i][1] < 0:\n",
    "        august_negative_BA.append(august_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        august_neutral_BA.append(august_sentiment_end_init_BA[i])  \n",
    "        \n",
    "august_positive_senti_BA = sentiment_new_test(august_positive_BA)\n",
    "august_negative_senti_BA = sentiment_new_test(august_negative_BA)\n",
    "august_neutral_senti_BA = sentiment_new_test(august_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "september_positive_BA = []\n",
    "september_neutral_BA = []\n",
    "september_negative_BA = []\n",
    "september_sentiment_end_init_BA = sentiment_delta_init_end(sep_con_dict_final_BA)\n",
    "for i in september_sentiment_end_init_BA:\n",
    "    if september_sentiment_end_init_BA[i][1] > 0:\n",
    "        september_positive_BA.append(september_sentiment_end_init_BA[i])\n",
    "    elif september_sentiment_end_init_BA[i][1] < 0:\n",
    "        september_negative_BA.append(september_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        september_neutral_BA.append(september_sentiment_end_init_BA[i])  \n",
    "        \n",
    "september_positive_senti_BA = sentiment_new_test(september_positive_BA)\n",
    "september_negative_senti_BA = sentiment_new_test(september_negative_BA)\n",
    "september_neutral_senti_BA = sentiment_new_test(september_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "october_positive_BA = []\n",
    "october_neutral_BA = []\n",
    "october_negative_BA = []\n",
    "october_sentiment_end_init_BA = sentiment_delta_init_end(oct_con_dict_final_BA)\n",
    "for i in october_sentiment_end_init_BA:\n",
    "    if october_sentiment_end_init_BA[i][1] > 0:\n",
    "        october_positive_BA.append(october_sentiment_end_init_BA[i])\n",
    "    elif october_sentiment_end_init_BA[i][1] < 0:\n",
    "        october_negative_BA.append(october_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        october_neutral_BA.append(october_sentiment_end_init_BA[i])  \n",
    "\n",
    "october_positive_senti_BA = sentiment_new_test(october_positive_BA)\n",
    "october_negative_senti_BA = sentiment_new_test(october_negative_BA)\n",
    "october_neutral_senti_BA = sentiment_new_test(october_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "november_positive_BA = []\n",
    "november_neutral_BA = []\n",
    "november_negative_BA = []\n",
    "november_sentiment_end_init_BA = sentiment_delta_init_end(nov_con_dict_final_BA)\n",
    "for i in november_sentiment_end_init_BA:\n",
    "    if november_sentiment_end_init_BA[i][1] > 0:\n",
    "        november_positive_BA.append(november_sentiment_end_init_BA[i])\n",
    "    elif november_sentiment_end_init_BA[i][1] < 0:\n",
    "        november_negative_BA.append(november_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        november_neutral_BA.append(november_sentiment_end_init_BA[i])  \n",
    "\n",
    "november_positive_senti_BA = sentiment_new_test(november_positive_BA)\n",
    "november_negative_senti_BA = sentiment_new_test(november_negative_BA)\n",
    "november_neutral_senti_BA = sentiment_new_test(november_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "december_positive_BA = []\n",
    "december_neutral_BA = []\n",
    "december_negative_BA = []\n",
    "december_sentiment_end_init_BA = sentiment_delta_init_end(dec_con_dict_final_BA)\n",
    "for i in december_sentiment_end_init_BA:\n",
    "    if december_sentiment_end_init_BA[i][1] > 0:\n",
    "        december_positive_BA.append(december_sentiment_end_init_BA[i])\n",
    "    elif december_sentiment_end_init_BA[i][1] < 0:\n",
    "        december_negative_BA.append(december_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        december_neutral_BA.append(december_sentiment_end_init_BA[i])  \n",
    "\n",
    "december_positive_senti_BA = sentiment_new_test(november_positive_BA)\n",
    "december_negative_senti_BA = sentiment_new_test(november_negative_BA)\n",
    "december_neutral_senti_BA = sentiment_new_test(november_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "january_positive_BA = []\n",
    "january_neutral_BA = []\n",
    "january_negative_BA = []\n",
    "january_sentiment_end_init_BA = sentiment_delta_init_end(jan_con_dict_final_BA)\n",
    "for i in january_sentiment_end_init_BA:\n",
    "    if january_sentiment_end_init_BA[i][1] > 0:\n",
    "        january_positive_BA.append(january_sentiment_end_init_BA[i])\n",
    "    elif january_sentiment_end_init_BA[i][1] < 0:\n",
    "        january_negative_BA.append(january_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        january_neutral_BA.append(january_sentiment_end_init_BA[i])  \n",
    "\n",
    "january_positive_senti_BA = sentiment_new_test(january_positive_BA)\n",
    "january_negative_senti_BA = sentiment_new_test(january_negative_BA)\n",
    "january_neutral_senti_BA = sentiment_new_test(january_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "february_positive_BA = []\n",
    "february_neutral_BA = []\n",
    "february_negative_BA = []\n",
    "february_sentiment_end_init_BA = sentiment_delta_init_end(feb_con_dict_final_BA)\n",
    "for i in february_sentiment_end_init_BA:\n",
    "    if february_sentiment_end_init_BA[i][1] > 0:\n",
    "        february_positive_BA.append(february_sentiment_end_init_BA[i])\n",
    "    elif february_sentiment_end_init_BA[i][1] < 0:\n",
    "        february_negative_BA.append(february_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        february_neutral_BA.append(february_sentiment_end_init_BA[i])  \n",
    "\n",
    "february_positive_senti_BA = sentiment_new_test(february_positive_BA)\n",
    "february_negative_senti_BA = sentiment_new_test(february_negative_BA)\n",
    "february_neutral_senti_BA = sentiment_new_test(february_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "march_positive_BA = []\n",
    "march_neutral_BA = []\n",
    "march_negative_BA = []\n",
    "march_sentiment_end_init_BA = sentiment_delta_init_end(march_con_dict_final_BA)\n",
    "for i in march_sentiment_end_init_BA:\n",
    "    if march_sentiment_end_init_BA[i][1] > 0:\n",
    "        march_positive_BA.append(march_sentiment_end_init_BA[i])\n",
    "    elif march_sentiment_end_init_BA[i][1] < 0:\n",
    "        march_negative_BA.append(march_sentiment_end_init_BA[i])\n",
    "    else:\n",
    "        march_neutral_BA.append(march_sentiment_end_init_BA[i])  \n",
    "\n",
    "march_positive_senti_BA = sentiment_new_test(march_positive_BA)\n",
    "march_negative_senti_BA = sentiment_new_test(march_negative_BA)\n",
    "march_neutral_senti_BA = sentiment_new_test(march_neutral_BA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BA_total_positive = may_positive_senti_BA + june_positive_senti_BA + july_positive_senti_BA + august_positive_senti_BA+september_positive_senti_BA + october_positive_senti_BA + november_positive_senti_BA +december_positive_senti_BA + january_positive_senti_BA + february_positive_senti_BA+march_positive_senti_BA\n",
    "BA_total_negative = may_negative_senti_BA + june_negative_senti_BA + july_negative_senti_BA + august_negative_senti_BA+september_negative_senti_BA+ october_negative_senti_BA + november_negative_senti_BA +december_negative_senti_BA + january_negative_senti_BA + february_negative_senti_BA+march_negative_senti_BA\n",
    "BA_total_neutral = may_neutral_senti_BA + june_neutral_senti_BA + july_neutral_senti_BA + august_neutral_senti_BA+september_neutral_senti_BA + october_neutral_senti_BA + november_neutral_senti_BA +december_neutral_senti_BA + january_neutral_senti_BA + february_neutral_senti_BA+march_neutral_senti_BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount_positive_positive_BA = 0\n",
    "amount_positive_negative_BA = 0\n",
    "amount_positive_neutral_BA = 0\n",
    "\n",
    "for i in BA_total_positive:\n",
    "    if i < -0.25:\n",
    "        amount_positive_negative_BA += 1\n",
    "    elif i > 0.25: \n",
    "        amount_positive_positive_BA +=1\n",
    "    else:\n",
    "        amount_positive_neutral_BA +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount_negative_positive_BA = 0\n",
    "amount_negative_negative_BA = 0\n",
    "amount_negative_neutral_BA = 0\n",
    "\n",
    "for i in BA_total_negative:\n",
    "    if i < -0.25:\n",
    "        amount_negative_negative_BA += 1\n",
    "    elif i > 0.25: \n",
    "        amount_negative_positive_BA +=1\n",
    "    else:\n",
    "        amount_negative_neutral_BA +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amount_neutral_positive_BA = 0\n",
    "amount_neutral_negative_BA = 0\n",
    "amount_neutral_neutral_BA = 0\n",
    "\n",
    "for i in BA_total_neutral:\n",
    "    if i < -0.25:\n",
    "        amount_neutral_negative_BA += 1\n",
    "    elif i > 0.25: \n",
    "        amount_neutral_positive_BA +=1\n",
    "    else:\n",
    "        amount_neutral_neutral_BA +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change_BA = pd.DataFrame({'index' : ['positive', 'negative', 'neutral'],'positive': [amount_positive_positive_BA, amount_positive_negative_BA, amount_positive_neutral_BA], \n",
    "                       'Negative': [amount_negative_positive_BA, amount_negative_negative_BA, amount_negative_neutral_BA],\n",
    "                     'Neutral' : [amount_neutral_positive_BA, amount_neutral_negative_BA, amount_neutral_neutral_BA ]\n",
    "                    })\n",
    "change_BA = change_BA.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize = (15, 5))\n",
    "\n",
    "sns.heatmap(change_KLM, ax = ax[0,0], square = True, vmax = 10000)\n",
    "ax[0,0].set_title(\"Sentiment change for KLM\", size=14, weight='bold')\n",
    "ax[0,0].set_ylabel('Sentiment delta')\n",
    "ax[0,0].set_xlabel('Initial Sentiment');\n",
    "\n",
    "sns.heatmap(change_BA, ax = ax[0,1], square = True, vmax = 10000)\n",
    "ax[0,1].set_title(\"Sentiment change for British Airways\", size=14, weight='bold')\n",
    "ax[0,1].set_ylabel('Sentiment delta')\n",
    "ax[0,1].set_xlabel('Initial Sentiment');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KLM_list_avg = [KLM_may_avg, KLM_june_avg, KLM_july_avg, KLM_august_avg, KLM_september_avg, KLM_october_avg, KLM_november_avg, \n",
    "               KLM_december_avg, KLM_january_avg, KLM_february_avg, KLM_march_avg]\n",
    "\n",
    "KLM_list_total = [KLM_may_total, KLM_june_total, KLM_july_total, KLM_august_total, KLM_september_total, KLM_october_total, \n",
    "                 KLM_november_total, KLM_december_total, KLM_january_total, KLM_february_total, KLM_march_total]\n",
    "\n",
    "BA_list_avg = [BA_may_avg, BA_june_avg, BA_july_avg, BA_august_avg, BA_september_avg, BA_october_avg, BA_november_avg, \n",
    "               BA_december_avg, BA_january_avg, BA_february_avg, BA_march_avg]\n",
    "\n",
    "BA_list_total = [BA_may_total, BA_june_total, BA_july_total, BA_august_total, BA_september_total, BA_october_total, \n",
    "                 BA_november_total, BA_december_total, BA_january_total, BA_february_total, BA_march_total]\n",
    "\n",
    "months = [\"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\",\"January\", \"February\", \"March\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index = np.arange(11)\n",
    "# bar_width = 0.35\n",
    "# fig, ax = plt.subplots()\n",
    "# bar_KLM = plt.bar(index, KLM_list_avg, bar_width, color = 'blue', label = 'KLM')\n",
    "# bar_BA = plt.bar(index + bar_width, BA_list_avg, bar_width, color = 'orange', label = 'BA' )\n",
    "# plt.xticks(index + (0.5 * bar_width), (months))\n",
    "# plt.legend()\n",
    "\n",
    "# ax.set_title(\"Average conversation length for KLM and BA per month\", size=16, weight='bold')\n",
    "# ax.set_ylabel(\"Average length\")\n",
    "\n",
    "# ax.set_xlabel(\"Month\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index = np.arange(11)\n",
    "# bar_width = 0.35\n",
    "# fig, ax = plt.subplots()\n",
    "# bar_KLM = plt.bar(index, KLM_list_total, bar_width, color = 'blue', label = 'KLM')\n",
    "# bar_BA = plt.bar(index + bar_width, BA_list_total, bar_width, color = 'orange', label = 'BA' )\n",
    "# plt.xticks(index + (0.5 * bar_width), (months))\n",
    "# plt.legend()\n",
    "\n",
    "# ax.set_title(\"Amount of conversations for KLM and BA per month\", size=16, weight='bold')\n",
    "# ax.set_ylabel(\"Total amount\")\n",
    "\n",
    "# ax.set_xlabel(\"Month\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sprint 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converting all the dates to weekdays\n",
    "def to_weekday(t):\n",
    "    if (t.dayofweek == 0):\n",
    "        return \"Monday\"\n",
    "    elif (t.dayofweek == 1):\n",
    "        return \"Tuesday\"\n",
    "    elif (t.dayofweek == 2):\n",
    "        return \"Wednesday\"\n",
    "    elif (t.dayofweek == 3):\n",
    "        return \"Thursday\"\n",
    "    elif (t.dayofweek == 4):\n",
    "        return \"Friday\"\n",
    "    elif (t.dayofweek == 5):\n",
    "        return \"Saturday\"\n",
    "    elif (t.dayofweek == 6):\n",
    "        return \"Sunday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extra function to make the heatmap looks more organized\n",
    "def to_weekday_heatmap(t):\n",
    "    if (t.dayofweek == 0):\n",
    "        return \"0 Monday\"\n",
    "    elif (t.dayofweek == 1):\n",
    "        return \"1 Tuesday\"\n",
    "    elif (t.dayofweek == 2):\n",
    "        return \"2 Wednesday\"\n",
    "    elif (t.dayofweek == 3):\n",
    "        return \"3 Thursday\"\n",
    "    elif (t.dayofweek == 4):\n",
    "        return \"4 Friday\"\n",
    "    elif (t.dayofweek == 5):\n",
    "        return \"5 Saturday\"\n",
    "    elif (t.dayofweek == 6):\n",
    "        return \"6 Sunday\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wintertime london\n",
    "def time_category(t):\n",
    "    if (t.hour >= 0) and (t.hour < 1):\n",
    "        return 0\n",
    "    elif (t.hour >= 1) and (t.hour < 2):\n",
    "        return 1\n",
    "    elif (t.hour >= 2) and (t.hour < 3):\n",
    "        return 2\n",
    "    elif (t.hour >= 3) and (t.hour < 4):\n",
    "        return 3\n",
    "    elif (t.hour >= 4) and (t.hour < 5):\n",
    "        return 4\n",
    "    elif (t.hour >= 5) and (t.hour < 6):\n",
    "        return 5\n",
    "    elif (t.hour >= 6) and (t.hour < 7):\n",
    "        return 6\n",
    "    elif (t.hour >= 7) and (t.hour < 8):\n",
    "        return 7\n",
    "    elif (t.hour >= 8) and (t.hour < 9):\n",
    "        return 8\n",
    "    elif (t.hour >= 9) and (t.hour < 10):\n",
    "        return 9\n",
    "    elif (t.hour >= 10) and (t.hour < 11):\n",
    "        return 10\n",
    "    elif (t.hour >= 11) and (t.hour < 12):\n",
    "        return 11\n",
    "    \n",
    "    elif (t.hour >= 12) and (t.hour < 13):\n",
    "        return 12\n",
    "    elif (t.hour >= 13) and (t.hour < 14):\n",
    "        return 13\n",
    "    elif (t.hour >= 14) and (t.hour < 15):\n",
    "        return 14\n",
    "    elif (t.hour >= 15) and (t.hour < 16):\n",
    "        return 15\n",
    "    elif (t.hour >= 16) and (t.hour < 17):\n",
    "        return 16\n",
    "    elif (t.hour >= 17) and (t.hour < 18):\n",
    "        return 17\n",
    "    elif (t.hour >= 18) and (t.hour < 19):\n",
    "        return 18\n",
    "    elif (t.hour >= 19) and (t.hour < 20):\n",
    "        return 19\n",
    "    elif (t.hour >= 20) and (t.hour < 21):\n",
    "        return 20\n",
    "    elif (t.hour >= 21) and (t.hour < 22):\n",
    "        return 21\n",
    "    elif (t.hour >= 22) and (t.hour < 23):\n",
    "        return 22\n",
    "    else:\n",
    "        return 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_category_KLM(t):\n",
    "    if (t.hour >= 0) and (t.hour < 1):\n",
    "        return 1\n",
    "    elif (t.hour >= 1) and (t.hour < 2):\n",
    "        return 2\n",
    "    elif (t.hour >= 2) and (t.hour < 3):\n",
    "        return 3\n",
    "    elif (t.hour >= 3) and (t.hour < 4):\n",
    "        return 4\n",
    "    elif (t.hour >= 4) and (t.hour < 5):\n",
    "        return 5\n",
    "    elif (t.hour >= 5) and (t.hour < 6):\n",
    "        return 6\n",
    "    elif (t.hour >= 6) and (t.hour < 7):\n",
    "        return 7\n",
    "    elif (t.hour >= 7) and (t.hour < 8):\n",
    "        return 8\n",
    "    elif (t.hour >= 8) and (t.hour < 9):\n",
    "        return 9\n",
    "    elif (t.hour >= 9) and (t.hour < 10):\n",
    "        return 10\n",
    "    elif (t.hour >= 10) and (t.hour < 11):\n",
    "        return 11\n",
    "    elif (t.hour >= 11) and (t.hour < 12):\n",
    "        return 12\n",
    "    \n",
    "    elif (t.hour >= 12) and (t.hour < 13):\n",
    "        return 13\n",
    "    elif (t.hour >= 13) and (t.hour < 14):\n",
    "        return 14\n",
    "    elif (t.hour >= 14) and (t.hour < 15):\n",
    "        return 15\n",
    "    elif (t.hour >= 15) and (t.hour < 16):\n",
    "        return 16\n",
    "    elif (t.hour >= 16) and (t.hour < 17):\n",
    "        return 17\n",
    "    elif (t.hour >= 17) and (t.hour < 18):\n",
    "        return 18\n",
    "    elif (t.hour >= 18) and (t.hour < 19):\n",
    "        return 19\n",
    "    elif (t.hour >= 19) and (t.hour < 20):\n",
    "        return 20\n",
    "    elif (t.hour >= 20) and (t.hour < 21):\n",
    "        return 21\n",
    "    elif (t.hour >= 21) and (t.hour < 22):\n",
    "        return 22\n",
    "    elif (t.hour >= 22) and (t.hour < 23):\n",
    "        return 23\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code and graphs for the percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_all = \"\"\"\n",
    "SELECT main.ID,Text,\"Created At\", \"Reply ID\", Date(\"Created At\") as Date, \"User ID\"\n",
    "FROM main, replies \n",
    "WHERE main.ID=replies.ID and (\"User ID\"= 56377143 or \"User ID\" = 18332190)\n",
    "ORDER BY Datetime(\"Created At\") desc\n",
    "\"\"\"\n",
    "df_response = pd.read_sql_query(query_all, conn)\n",
    "df_response[\"Reply_timestamp\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for key, value in df_response.iteritems():\n",
    "    if key == \"Reply ID\":\n",
    "        lst = value\n",
    "        for i in lst:\n",
    "            if str(i) in time_dict: \n",
    "                df_response.loc[counter, \"Reply_timestamp\"] = time_dict.get(i)\n",
    "                counter += 1\n",
    "            else:\n",
    "                df_response.loc[counter, \"Reply_timestamp\"] = 0\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_replies = df_response[df_response[\"Reply_timestamp\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_time_delta = []\n",
    "for row in df_replies[[\"Created At\", \"Reply_timestamp\"]].iterrows():\n",
    "    time = row[1]\n",
    "    datetime_object1 = datetime.datetime.strptime(time[0], '%Y-%m-%d %H:%M:%S+00:00')\n",
    "    datetime_object2 = datetime.datetime.strptime(time[1], '%Y-%m-%d %H:%M:%S+00:00')\n",
    "    \n",
    "    delta = abs(datetime_object1- datetime_object2)\n",
    "    list_time_delta += [delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_replies[\"Time delta\"]= list_time_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_replies[\"Date\"] = pd.to_datetime(df_replies[\"Created At\"])\n",
    "\n",
    "df_replies_klm = df_replies[df_replies[\"User ID\"] == \"56377143\"] \n",
    "df_replies_ba = df_replies[df_replies[\"User ID\"] == \"18332190\"]  \n",
    "\n",
    "df_replies_klm[\"Time_category\"] = [time_category_KLM(x) for x in df_replies_klm[\"Date\"]]\n",
    "df_replies_ba[\"Time_category\"] = [time_category(x) for x in df_replies_ba[\"Date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_replies_klm[\"Minutes\"] = [x.hour *60 + x.minute +x.second/60 for x in pd.to_datetime(df_replies_klm[\"Time delta\"])]\n",
    "df_replies_ba[\"Minutes\"] = [x.hour *60 + x.minute +x.second/60 for x in pd.to_datetime(df_replies_ba[\"Time delta\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_plot_klm = pd.DataFrame(df_replies_klm.groupby(['Time_category'])[\"Minutes\"].mean())\n",
    "df_plot_ba = pd.DataFrame(df_replies_ba.groupby(['Time_category'])[\"Minutes\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_time_tweets_klm[\"Date\"] = pd.to_datetime(df_time_tweets_klm[\"Created At\"])\n",
    "df_time_tweets_klm[\"Time_category\"] = [time_category_KLM(x) for x in df_time_tweets_klm[\"Date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_time_tweets_ba[\"Date\"] = pd.to_datetime(df_time_tweets_ba[\"Created At\"])\n",
    "df_time_tweets_ba[\"Time_category\"] = [time_category(x) for x in df_time_tweets_ba[\"Date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_time_category_klm = pd.DataFrame(df_time_tweets_klm.groupby(['Time_category']).count())\n",
    "df_time_category_ba = pd.DataFrame(df_time_tweets_ba.groupby(['Time_category']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "x = [list(df_plot_klm.index)] #hours\n",
    "s = [n for n in df_plot_klm[\"Minutes\"]]\n",
    "y = list(df_time_category_klm[\"Created At\"])\n",
    "\n",
    "x2 = [list(df_plot_ba.index)] #hours\n",
    "s2 = [n for n in df_plot_ba[\"Minutes\"]]\n",
    "y2 = list(df_time_category_ba[\"Created At\"])\n",
    "\n",
    "ax.scatter(x2, y2, s2, color =\"Orange\")\n",
    "ax.scatter(x, y, s, color =\"#0000FF\")\n",
    "\n",
    "ba_legend = mpatches.Patch(color='Orange', label='BA')\n",
    "klm_legend = mpatches.Patch(color='#0000FF', label='KLM')\n",
    "\n",
    "for time in [50, 150, 300, 450]:\n",
    "    plt.scatter([], [], c='orange', alpha=0.3, s=time,\n",
    "                label=str(time) + ' Mins')\n",
    "\n",
    "leg1 = ax.legend(loc='upper left', scatterpoints=1, frameon=False, labelspacing=1, title='Response time')\n",
    "leg2 = ax.legend(handles = [ba_legend, klm_legend], title = \"Airline\", loc = 'upper right')\n",
    "\n",
    "ax.add_artist(leg1)\n",
    "txt=\"Hours of the day \\n \\n This plot shows the total number of tweets per hour of the day on the x and y axes. \\n The colors indicate the airline and the size of the points show the response time\"\n",
    "plt.xlabel(txt)\n",
    "plt.ylabel(\"Number of tweets\")\n",
    "plt.title(\"Total number of tweets and response time per hour of the day per airline\", size = 16, weight = 'bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ba_total[\"Date\"] = pd.to_datetime(df_ba_total[\"Created At\"])\n",
    "df_ba_total[\"Time_category\"] = [time_category(x) for x in df_ba_total[\"Date\"]]\n",
    "\n",
    "df_klm_total[\"Date\"] = pd.to_datetime(df_klm_total[\"Created At\"])\n",
    "df_klm_total[\"Time_category\"] = [time_category_KLM(x) for x in df_klm_total[\"Date\"]]\n",
    "\n",
    "df_ba_sent[\"Date\"] = pd.to_datetime(df_ba_total[\"Created At\"])\n",
    "df_ba_sent[\"Time_category\"] = [time_category(x) for x in df_ba_sent[\"Date\"]]\n",
    "\n",
    "df_klm_sent[\"Date\"] = pd.to_datetime(df_klm_total[\"Created At\"])\n",
    "df_klm_sent[\"Time_category\"] = [time_category(x) for x in df_klm_sent[\"Date\"]]\n",
    "\n",
    "klm_sent = df_klm_sent.groupby(['Time_category']).count()\n",
    "\n",
    "ba_sent = df_ba_sent.groupby(['Time_category']).count()\n",
    "\n",
    "klm_all = df_klm_total.groupby(['Time_category']).count()\n",
    "\n",
    "ba_all = df_ba_total.groupby(['Time_category']).count()\n",
    "\n",
    "percentage_ba = pd.DataFrame(ba_sent[\"ID\"]/ba_all[\"ID\"])\n",
    "percentage_klm = pd.DataFrame(klm_sent[\"ID\"]/klm_all[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.arange(percentage_ba.shape[0])\n",
    "hours = [n for n in range(percentage_ba.shape[0])]\n",
    "bar_width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "bar_KLM_perc = plt.bar(index, list(percentage_klm[\"ID\"]), bar_width, color = 'blue', label = 'KLM')\n",
    "bar_BA_perc = plt.bar(index + bar_width, list(percentage_ba[\"ID\"]), bar_width, color = 'orange', label = 'BA' )\n",
    "\n",
    "plt.xticks(index + (0.5 * bar_width), hours)\n",
    "plt.legend()\n",
    "\n",
    "ax.set_title(\"Tweets by KLM and BA: percentage of their tweet volume\", size=16, weight='bold')\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "ax.set_xlabel(\"Hour of the day\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_total_comparison = pd.DataFrame({'Positive': [len(KLM_total_positive), len(BA_total_positive)], \n",
    "                              'Negative': [len(KLM_total_negative),  len(BA_total_negative)], \n",
    "                              'Neutral': [len(KLM_total_neutral),  len(BA_total_neutral)]}, \n",
    "                                    index = pd.Index(['KLM', 'BA'],name = 'Airline' ))\n",
    "\n",
    "sent_total_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "barWidth = 0.25\n",
    "\n",
    "total_KLM = len(KLM_total_positive) + len(KLM_total_negative) + len(KLM_total_neutral)\n",
    "total_BA = len(BA_total_positive) + len(BA_total_negative) + len(BA_total_neutral)\n",
    "\n",
    "bar1 = [len(KLM_total_positive)/total_KLM, len(KLM_total_negative)/total_KLM, len(KLM_total_neutral)/total_KLM]\n",
    "bar2 = [len(BA_total_positive)/total_BA, len(BA_total_negative)/total_BA, len(BA_total_neutral)/total_BA]\n",
    "\n",
    "r1 = np.arange(len(bar1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "plt.bar(r1, bar1, color='blue', width=barWidth, edgecolor='white', label='KLM')\n",
    "plt.bar(r2, bar2, color='orange', width=barWidth, edgecolor='white', label='BA')\n",
    "\n",
    "plt.xlabel('Sentiment category')\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title(\"Percentage tweets per category for KLM and BA\", fontsize = 16, fontweight = \"bold\")\n",
    "plt.xticks([r + barWidth for r in range(len(bar1))], ['Positive', 'Negative', 'Neutral'])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
